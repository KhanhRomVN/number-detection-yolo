{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train annotations:  11%|â–ˆ         | 111/1032 [00:00<00:01, 874.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PROCESSED_DIR, subset), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xml_file \u001b[38;5;129;01min\u001b[39;00m tqdm(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RAW_DIR, subset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.xml\u001b[39m\u001b[38;5;124m\"\u001b[39m)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m annotations\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mconvert_annotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_file \u001b[38;5;129;01min\u001b[39;00m tqdm(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RAW_DIR, subset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     59\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(img_file, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PROCESSED_DIR, subset))\n",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m, in \u001b[0;36mconvert_annotation\u001b[1;34m(xml_file, class_map)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_annotation\u001b[39m(xml_file, class_map):\n\u001b[1;32m---> 22\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mET\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     root \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[0;32m     25\u001b[0m     size \u001b[38;5;241m=\u001b[39m root\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\xml\\etree\\ElementTree.py:1204\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(source, parser)\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse XML document into element tree.\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m \n\u001b[0;32m   1197\u001b[0m \u001b[38;5;124;03m*source* is a filename or file object containing XML data,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1201\u001b[0m \n\u001b[0;32m   1202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m tree \u001b[38;5;241m=\u001b[39m ElementTree()\n\u001b[1;32m-> 1204\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\xml\\etree\\ElementTree.py:558\u001b[0m, in \u001b[0;36mElementTree.parse\u001b[1;34m(self, source, parser)\u001b[0m\n\u001b[0;32m    556\u001b[0m close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 558\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m     close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set up paths\n",
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, \"data\")\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "MODEL_DIR = os.path.join(PROJECT_DIR, \"models\")\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Function to convert XML annotations to YOLO format\n",
    "def convert_annotation(xml_file, class_map):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    size = root.find('size')\n",
    "    w = int(size.find('width').text)\n",
    "    h = int(size.find('height').text)\n",
    "    \n",
    "    out_file = xml_file.replace('.xml', '.txt').replace(RAW_DIR, PROCESSED_DIR)\n",
    "    \n",
    "    with open(out_file, 'w') as f:\n",
    "        for obj in root.iter('object'):\n",
    "            cls = obj.find('name').text\n",
    "            if cls not in class_map:\n",
    "                continue\n",
    "            cls_id = class_map[cls]\n",
    "            xmlbox = obj.find('bndbox')\n",
    "            b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text), float(xmlbox.find('ymax').text))\n",
    "            bb = ((b[0] + b[1]) / 2 / w, (b[2] + b[3]) / 2 / h, (b[1] - b[0]) / w, (b[3] - b[2]) / h)\n",
    "            f.write(f\"{cls_id} {bb[0]:.6f} {bb[1]:.6f} {bb[2]:.6f} {bb[3]:.6f}\\n\")\n",
    "\n",
    "# Get all classes\n",
    "classes = set()\n",
    "for xml_file in glob.glob(os.path.join(RAW_DIR, \"train\", \"*.xml\")):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    for obj in root.iter('object'):\n",
    "        classes.add(obj.find('name').text)\n",
    "\n",
    "class_map = {cls: idx for idx, cls in enumerate(sorted(classes))}\n",
    "\n",
    "# Convert annotations and copy images\n",
    "for subset in ['train', 'valid']:\n",
    "    os.makedirs(os.path.join(PROCESSED_DIR, subset), exist_ok=True)\n",
    "    for xml_file in tqdm(glob.glob(os.path.join(RAW_DIR, subset, \"*.xml\")), desc=f\"Converting {subset} annotations\"):\n",
    "        convert_annotation(xml_file, class_map)\n",
    "        \n",
    "    for img_file in tqdm(glob.glob(os.path.join(RAW_DIR, subset, \"*.jpg\")), desc=f\"Copying {subset} images\"):\n",
    "        shutil.copy(img_file, os.path.join(PROCESSED_DIR, subset))\n",
    "\n",
    "# Create dataset.yaml file\n",
    "dataset_config = {\n",
    "    'path': PROCESSED_DIR,\n",
    "    'train': os.path.join(PROCESSED_DIR, 'train'),\n",
    "    'val': os.path.join(PROCESSED_DIR, 'valid'),\n",
    "    'test': os.path.join(RAW_DIR, 'test'),  # Assuming test set is in RAW_DIR\n",
    "    'nc': len(class_map),\n",
    "    'names': list(class_map.keys())\n",
    "}\n",
    "\n",
    "with open(os.path.join(PROCESSED_DIR, 'dataset.yaml'), 'w') as f:\n",
    "    yaml.dump(dataset_config, f)\n",
    "\n",
    "print(\"Dataset preparation completed.\")\n",
    "\n",
    "# Train model for project\n",
    "model_project = YOLO('yolov8n.yaml')\n",
    "try:\n",
    "    results_project = model_project.train(\n",
    "        data=os.path.join(PROCESSED_DIR, 'dataset.yaml'),\n",
    "        epochs=50,  # Reduced from 100\n",
    "        imgsz=416,  # Reduced from 640\n",
    "        batch=32,   # Increased from 16\n",
    "        device='0' if torch.cuda.is_available() else 'cpu',\n",
    "        project=MODEL_DIR,\n",
    "        name='number_detection_project'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error training project model: {e}\")\n",
    "\n",
    "# Train model for web\n",
    "model_web = YOLO('yolov8n.yaml')\n",
    "try:\n",
    "    results_web = model_web.train(\n",
    "        data=os.path.join(PROCESSED_DIR, 'dataset.yaml'),\n",
    "        epochs=25,  # Reduced from 50\n",
    "        imgsz=320,  # Reduced from 416\n",
    "        batch=64,   # Increased from 32\n",
    "        device='0' if torch.cuda.is_available() else 'cpu',\n",
    "        project=MODEL_DIR,\n",
    "        name='number_detection_web'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error training web model: {e}\")\n",
    "\n",
    "# Evaluate the models\n",
    "try:\n",
    "    results_project = model_project.val()\n",
    "    results_web = model_web.val()\n",
    "    print(\"Project model evaluation results:\")\n",
    "    print(results_project)\n",
    "    print(\"\\nWeb model evaluation results:\")\n",
    "    print(results_web)\n",
    "except Exception as e:\n",
    "    print(f\"Error evaluating models: {e}\")\n",
    "\n",
    "# Save the trained models\n",
    "try:\n",
    "    model_project.save(os.path.join(MODEL_DIR, 'number_detection_project.pt'))\n",
    "    model_web.save(os.path.join(MODEL_DIR, 'number_detection_web.pt'))\n",
    "    print(\"Models saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving models: {e}\")\n",
    "\n",
    "print(\"Training completed. Models saved in:\", MODEL_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
